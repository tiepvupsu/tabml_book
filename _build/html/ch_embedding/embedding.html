
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Embedding &#8212; Machine Learning cho dữ liệu dạng bảng</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://machinelearningcoban.com/tabml_book/ch_embedding/embedding.html" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Word2vec" href="word2vec.html" />
    <link rel="prev" title="Đặc trưng dạng số (WIP)" href="../ch_data_processing/numeric_data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning cho dữ liệu dạng bảng</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/properties.html">
   Đặc điểm của dữ liệu dạng bảng
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/pipeline.html">
   Machine Learning pipeline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/why_pipeline.html">
   Tại sao cần xây dựng pipeline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/tabml.html">
   Thư viện tabml đi kèm cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/titanic_pipeline.html">
   Pipeline đơn giản cho cuộc thi Titanic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Bố cục cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/contributions.html">
   Đóng góp vào dự án
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/datasets.html">
   Các bộ dữ liệu sử dụng trong sách
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Kỹ thuật xử lý dữ liệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_data_processing/eda.html">
   Phân tích Khám phá Dữ liệu - EDA
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/eda_purpose.html">
     Mục đích của EDA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/eda_titanic.html">
     EDA cho dữ liệu Titanic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/eda_cali_housing.html">
     EDA cho dữ liệu California Housing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/pandas-profiling.html">
     Pandas profiling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_data_processing/data_cleaning.html">
   Làm sạch dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/process_outliers.html">
     Xử lý các giá trị ngoại lệ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/process_missing.html">
     Xử lý dữ liệu bị khuyết
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_data_processing/categorical_data.html">
   Đặc trưng hạng mục (WIP)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/onehot.html">
     Mã hóa one-hot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/hashing.html">
     Hashing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_data_processing/crossing.html">
     Crossing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_data_processing/numeric_data.html">
   Đặc trưng dạng số (WIP)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Embedding
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Embedding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="word2vec.html">
   Word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="product2vec.html">
   Instacart Product2vec
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Hệ thống gợi ý
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_recommendation_system/introduction.html">
   Hệ thống gợi ý
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_recommendation_system/ml_1m.html">
   Bộ dữ liệu MovieLens-1M
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_recommendation_system/content_based.html">
   Hệ thống dựa trên nội dung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_recommendation_system/matrix_factorization.html">
   Matrix Factorization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_recommendation_system/factorization_machine.html">
   Factorization machine
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Đóng góp từ tác giả khác
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_data_processing/timeseries_data.html">
   Dữ liệu chuỗi thời gian
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_model/decision_tree.html">
   Decision Tree algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_model/random_forest.html">
   Random Forest algorithm
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ap/visualization.html">
   Minh họa dữ liệu
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_embedding/embedding.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_embedding/embedding.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/tiepvupsu/tabml_book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/tiepvupsu/tabml_book/issues/new?title=Issue%20on%20page%20%2Fch_embedding/embedding.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/tiepvupsu/tabml_book/edit/main/book/ch_embedding/embedding.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/tiepvupsu/tabml_book/main?urlpath=tree/book/ch_embedding/embedding.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Embedding
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gioi-thieu">
     Giới thiệu
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bieu-dien-toan-hoc">
     Biểu diễn toán học
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tao-embedding-nhu-the-nao">
     Tạo embedding như thế nào?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-tuong-tu-giua-hai-embedding">
   Độ tương tự giữa hai embedding
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#khoang-cach-euclid">
     Khoảng cách Euclid
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tich-vo-huong">
     Tích vô hướng
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tuong-tu-cosine">
     Tương tự cosine
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tim-embedding-gan-nhat">
     Tìm embedding gần nhất
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="embedding">
<span id="sec-embedding"></span><h1>Embedding<a class="headerlink" href="#embedding" title="Permalink to this headline">¶</a></h1>
<div class="section" id="gioi-thieu">
<h2>Giới thiệu<a class="headerlink" href="#gioi-thieu" title="Permalink to this headline">¶</a></h2>
<p>Embedding là một kỹ thuật đưa một vector có số chiều lớn, thường ở dạng thưa, về một vector có số chiều nhỏ, thường ở dạng dày đặc.
Phương pháp này đặc biệt hữu ích với những đặc trưng hạng mục có số phần tử lớn ở đó phương pháp chủ yếu để biểu diễn mỗi giá trị thường là một vector dạng one-hot.
Một cách lý tưởng, các giá trị có ý nghĩa tương tự nhau nằm gần nhau trong không gian embedding.</p>
<p>Ví dụ nổi bật nhất là biểu diễn các từ trong một bộ từ điển dưới dạng số. Khi từ điển có hàng triệu từ, biểu diễn các từ dưới dạng one-hot vector dẫn tới số chiều vô cùng lớn.
Hơn nữa, các từ này sẽ có khoảng cách đều nhau tới mọi từ khác (căn bậc hai của 2), dẫn đến việc thiếu thông tin giá trị cho việc huấn luyện mô hình machine learning.
Chẳng hạn, một cách biểu diễn tốt các từ tiếng Việt cần mô tả tốt sự liên quan giữa cặp từ (vua, hoàng hậu) và (chồng, vợ) vì chúng có ý nghĩa gần nhau.</p>
</div>
<div class="section" id="bieu-dien-toan-hoc">
<h2>Biểu diễn toán học<a class="headerlink" href="#bieu-dien-toan-hoc" title="Permalink to this headline">¶</a></h2>
<p>Giả sử một từ điển nào đó chỉ có sáu giá trị (Hà Nội, Hải Phòng, Tp HCM, Bình Dương, Lào Cai, Sóc Trăng). <a class="reference internal" href="#img-onehot-emb"><span class="std std-numref">Fig. 7</span></a> thể hiện cách biểu diễn của các giá trị này trong không gian one-hot và không gian embedding hai chiều.</p>
<div class="figure align-default" id="img-onehot-emb">
<img alt="../_images/emb1.png" src="../_images/emb1.png" />
<p class="caption"><span class="caption-number">Fig. 7 </span><span class="caption-text">Biểu diễn các giá trị hạng mục dưới dạng one-hot vector và embedding</span><a class="headerlink" href="#img-onehot-emb" title="Permalink to this image">¶</a></p>
</div>
<p>Ở đây, các giá trị trong không gian embedding được lấy ví dụ bằng tay với chiều thứ nhất thể hiện dân số và chiều thứ hai thể hiện vĩ độ đã chuẩn hóa của mỗi giá trị. Vị trí của mỗi vector embedding trong không gian hai chiều được minh hoạ trong <a class="reference internal" href="#img-exp-emb-viz"><span class="std std-numref">Fig. 8</span></a>. Trong không gian này, Hà Nội, Hải Phòng và Hà Giang gần nhau về vị trí địa lý. Nếu chúng ta có một bài toán nào đó mà dân số có thể là một đặc trưng tốt, ta chỉ cần co trục tung và giãn trục hoành là có thể mang những tỉnh thành có dân số giống nhau gần với nhau hơn.</p>
<div class="figure align-default" id="img-exp-emb-viz">
<img alt="../_images/emb2.png" src="../_images/emb2.png" />
<p class="caption"><span class="caption-number">Fig. 8 </span><span class="caption-text">Biểu diễn các vector embedding trong không gian</span><a class="headerlink" href="#img-exp-emb-viz" title="Permalink to this image">¶</a></p>
</div>
<p>Với một từ điển bất kỳ với <span class="math notranslate nohighlight">\(N\)</span> từ <span class="math notranslate nohighlight">\((w_1, w_2, \dots, w_{N})\)</span>. Giả sử số chiều của không gian embedding là <span class="math notranslate nohighlight">\(d\)</span>, ta có thể biểu diễn toàn bộ các embedding cho <span class="math notranslate nohighlight">\(N\)</span> từ này dưới dạng một ma trận <span class="math notranslate nohighlight">\(\mathbf{E} \in \mathbb{R}^{N\times k}\)</span> với hàng thứ <span class="math notranslate nohighlight">\(i\)</span> là biểu diễn embedding cho từ <span class="math notranslate nohighlight">\(w_{i}\)</span>.</p>
<p>Nếu vector <span class="math notranslate nohighlight">\(\mathbf{o}_i \in \mathbb{R}^{N \times 1}\)</span> là biểu diễn one-hot của từ <span class="math notranslate nohighlight">\(w_i\)</span>, ta có ngay <span class="math notranslate nohighlight">\(\mathbf{e} = \mathbf{o}_i^T\mathbf{E} \in \mathbb{R}^{1 \times k}\)</span> là biểu diễn của từ đó trong không gian embedding.</p>
</div>
<div class="section" id="tao-embedding-nhu-the-nao">
<h2>Tạo embedding như thế nào?<a class="headerlink" href="#tao-embedding-nhu-the-nao" title="Permalink to this headline">¶</a></h2>
<p>Cách biểu diễn các tỉnh thành trong ví dụ trên đây chỉ là một ví dụ minh họa khi chúng ta có thể định nghĩa các trục một cách cụ thể dựa vào kiến thức nhất định đã có về dữ liệu. Cách làm này không khả thi với những dữ liệu vô cùng nhiều chiều và không có những ý nghĩa từng trục rõ ràng như trên. Việc tìm ra ma trận <span class="math notranslate nohighlight">\(\mathbf{E}\)</span> cần thông qua một quá trình “học” dựa trên mối quan hệ vốn có của dữ liệu.</p>
<p>Ta có thể thấy rằng ma trận <span class="math notranslate nohighlight">\(\mathbf{E}\)</span> có thể được coi là một ma trận trọng số của một tầng tuyến tính trong một mạng neural nhân tạo như trong <a class="reference internal" href="#img-exp-emb-neural"><span class="std std-numref">Fig. 9</span></a>.</p>
<div class="figure align-default" id="img-exp-emb-neural">
<img alt="../_images/emb3.png" src="../_images/emb3.png" />
<p class="caption"><span class="caption-number">Fig. 9 </span><span class="caption-text">Ma trận embedding có thể coi là một ma trận trọng số trong một mạng neural nhân tạo.</span><a class="headerlink" href="#img-exp-emb-neural" title="Permalink to this image">¶</a></p>
</div>
<p>Như vậy, ma trận này cũng có thể được xây dựng bằng cách đặt nó vào một mạng neural với một hàm mất mát nào đó. Trong Tensorflow (phiên bản 2.5), tầng embedding có thể được khai báo bởi <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Embedding</span></code></a>. Trong Pytorch 1.8.1, ta có thể dùng <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code class="docutils literal notranslate"><span class="pre">torch.nn.Embedding</span></code></a>. Trong cuốn sách này, chúng ta sẽ có một ví dụ về việc xây dựng embedding cho các sản phẩm dựa trên nền tảng Pytorch.</p>
<p>Embedding có thể được học trong cả một bài toán tổng thể hoặc học riêng rẽ khác trước khi đưa vào một bài toán cụ thể. Embedding thu được có thể được dùng như một đặc trưng nhiều chiều và có thể trong các mô hình không phải học sâu.</p>
<p>Word2vec là một trong những phương pháp tiên phong về việc xây dựng embedding cho các từ dựa trên một mạng học sâu. Các vector embedding này được học chỉ dựa trên thứ tự các từ trong câu của một bộ dữ liệu lớn mà không cần biết ý nghĩa cụ thể của từng câu hay mối quan hệ đặc biệt nào giữa chúng. Các vector embedding này có thể được dùng để tạo các biểu diễn cho một câu hay một văn bản để giải quyết các bài toán khác.</p>
</div>
</div>
<div class="section" id="do-tuong-tu-giua-hai-embedding">
<h1>Độ tương tự giữa hai embedding<a class="headerlink" href="#do-tuong-tu-giua-hai-embedding" title="Permalink to this headline">¶</a></h1>
<p>Quay lại với mục đích chính của việc tạo embedding là đưa các giá trị hạng mục về một không gian số sao cho embedding của những giá trị tương tự nằm <em>gần</em> nhau trong không gian. Vậy <em>khoảng cách</em> này thường được tính như thế nào.</p>
<p>Có ba phép đo thường được sử dụng để tính khoảng cách giữa hai embedding là khoảng cách Euclid, tích vô hướng của hai vector, và độ tương tự cosine.</p>
<div class="section" id="khoang-cach-euclid">
<h2>Khoảng cách Euclid<a class="headerlink" href="#khoang-cach-euclid" title="Permalink to this headline">¶</a></h2>
<p>Công thức tính khoảng cách Euclid giữa hai vector embedding</p>
<div class="math notranslate nohighlight">
\[
d_1(\mathbf{e}_1, \mathbf{e}_2) = \|\mathbf{e}_1 - \mathbf{e}_2\| = \sqrt{\|\mathbf{e}_1\|^2 + \|\mathbf{e}_2\|^2 - 2\mathbf{e}_1^T\mathbf{e}_2}
\]</div>
<p>Khoảng cách này không âm và càng nhỏ thì hai vector embedding càng gần nhau. Ở đây, <span class="math notranslate nohighlight">\(\|\mathbf{e}\| = \sqrt{\sum_{i=1}^d e_i^2}\)</span> là độ lớn của vector <span class="math notranslate nohighlight">\(\mathbf{e} \in \mathbb{R}^d\)</span>.</p>
<p>Để giảm sự phức tạp khi khai căn, bình phương khoảng cách Euclid thường được sử dụng. Việc lấy bình phương không ảnh hưởng tới việc so sánh khoảng cách vì bình phương là một hàm đồng biến.</p>
<div class="math notranslate nohighlight">
\[
d_2(\mathbf{e}_1, \mathbf{e}_2) = \|\mathbf{e}_1 - \mathbf{e}_2\|^2 = \|\mathbf{e}_1\|^2 + \|\mathbf{e}_2\|^2 - 2\mathbf{e}_1^T\mathbf{e}_2
\]</div>
</div>
<div class="section" id="tich-vo-huong">
<h2>Tích vô hướng<a class="headerlink" href="#tich-vo-huong" title="Permalink to this headline">¶</a></h2>
<p>Công thức tính độ tương tự theo tích vô hướng (<em>dot product</em>) giữa hai vector embedding:</p>
<div class="math notranslate nohighlight">
\[
\textrm{similar_dot}(\mathbf{e}_1, \mathbf{e_2}) = \mathbf{e}_1^T\mathbf{e_2}
\]</div>
<p>Tính vô hướng giữa hai vector càng cao thể hiện các embedding càng giống nhau. Giá trị này lớn nếu góc giữa hai vector  nhỏ và các vector này có độ dài lớn.</p>
</div>
<div class="section" id="tuong-tu-cosine">
<h2>Tương tự cosine<a class="headerlink" href="#tuong-tu-cosine" title="Permalink to this headline">¶</a></h2>
<p>Tương tự cosin cũng được sử dụng để đo độ tương tự giữa hai vector:</p>
<div class="math notranslate nohighlight">
\[
\textrm{similar_cosine}(\mathbf{e}_1, \mathbf{e}_2) = \frac{\mathbf{e}_1^T\mathbf{e}_2}{\|\mathbf{e}_1\| \|\mathbf{e}_2\|}
\]</div>
<p>Góc giữa hai vector càng nhỏ thì độ tương tự cosin càng cao. Độ tương tự cosin nhỏ nhất bằng -1 nếu hai vector này trái dấu nhau.</p>
<p>Trong ba độ đo trên đây, tích vô hướng có công thức đơn giản nhất và thường được sử dụng trong các bài toán quy mô lớn. Tương tự cosine không quan tâm tới độ lớn của hai vector mà chỉ xét tới góc giữa chúng, phép đo này phù hợp với các bài toán yêu cầu tìm sự trái ngược giữa các giá trị hạng mục. Nếu các vector embedding có cùng độ dài, ba phép đo này có ý nghĩa như nhau.</p>
</div>
<div class="section" id="tim-embedding-gan-nhat">
<h2>Tìm embedding gần nhất<a class="headerlink" href="#tim-embedding-gan-nhat" title="Permalink to this headline">¶</a></h2>
<p>Embedding được dùng nhiều trong bài toán tìm kiếm các điểm trong cơ sở dữ liệu (<em>item embeddings</em>) gần nhất với một embedding truy vấn (<em>query embedding</em>) nào đó.</p>
<p>Giả sử <span class="math notranslate nohighlight">\(\mathbf{E} \in \mathbb{R}^{N\times d}\)</span> và <span class="math notranslate nohighlight">\(\mathbf{q} \in \mathbb{R}^d\)</span> lần lượt là ma trận embedding của các giá trị trong cơ sở dữ liệu và vector truy vấn.</p>
<p>Với <strong>khoảng cách Euclid</strong>, khoảng cách giữa <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> và một embedding <span class="math notranslate nohighlight">\(\mathbf{e}_i\)</span> trong <span class="math notranslate nohighlight">\(\mathbf{E}\)</span> được tính bởi:</p>
<div class="math notranslate nohighlight">
\[
d_2(\mathbf{q}, \mathbf{e}_i) = \|\mathbf{q}\|^2 + \|\mathbf{e}_i\|^2 - 2\mathbf{q}^T\mathbf{e}_i
\]</div>
<p>Chỉ số của embedding gần <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> được tính bởi:</p>
<div class="math notranslate nohighlight">
\[
\arg \min_{i} d_2(\mathbf{q}, \mathbf{e}_i) = \arg \min_{i} \left(\|\mathbf{e}_i\|^2 - 2\mathbf{q}^T\mathbf{e}_i \right)
\]</div>
<p>Với <strong>độ tương tự tích vô hướng</strong>, chỉ số của embedding gần <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> được tính như sau:</p>
<div class="math notranslate nohighlight">
\[
\arg \max_i \mathbf{q}^T\mathbf{e}_i = \arg \min_i \left(- \mathbf{q}^T\mathbf{e}_i\right)
\]</div>
<p>Với <strong>độ tương tự cosine</strong>, chỉ số của embedding gần <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> được tính bởi:</p>
<div class="math notranslate nohighlight">
\[
\arg \max_i \frac{\mathbf{q}^T\mathbf{e}_i}{\|\mathbf{q}\| \|\mathbf{e}_i\|} = \arg \min_i \left(- \frac{\mathbf{q}^T\mathbf{e}_i}{\|\mathbf{e}_i\|}\right)
\]</div>
<p>Bài toán đi tìm những điểm trong cơ sở dữ liệu có embedding gần với một embedding cho trước có thể được triển khai như sau:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">class</span> <span class="nc">NearestNeighbor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Class supporting finding neareast embeddings of a query embeddings.</span>

<span class="sd">    Attrubutes:</span>
<span class="sd">        item_embeddings: a matrix of shape [N, k], such that row i is the embedding of</span>
<span class="sd">            item i.</span>
<span class="sd">        measure: One of (&quot;cosine&quot;, &quot;dot&quot;, &quot;l2&quot;) specifying the similarity measure to be used</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">,</span> <span class="n">measure</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">measure</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;dot&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine&quot;</span><span class="p">,</span> <span class="s2">&quot;l2&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">=</span> <span class="n">measure</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">item_embeddings</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
            <span class="c1"># nomalize embeding</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">item_embeddings</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                <span class="n">item_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">==</span> <span class="s2">&quot;l2&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">squared_item_embedding</span> <span class="o">=</span> <span class="p">(</span><span class="n">item_embeddings</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">find_nearest_neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_embedding</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns indices of k nearest neighbors&quot;&quot;&quot;</span>
        <span class="c1"># Denote q as query_emebdding vector, V as item_embeddings matrix.</span>
        <span class="n">dot_products</span> <span class="o">=</span> <span class="n">query_embedding</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;dot&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine&quot;</span><span class="p">):</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">dot_products</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">==</span> <span class="s2">&quot;l2&quot;</span><span class="p">:</span>
            <span class="c1"># ignore squared_query_embedding since it&#39;s the same for all item_embeddings</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">squared_item_embedding</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dot_products</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="n">k</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">test_nearest_neighbors</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">],</span>  <span class="c1"># neareast in l2</span>
            <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span>  <span class="c1"># neareast in dot product similarity</span>
            <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>  <span class="c1"># nearest in cosine similarity</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="k">assert</span> <span class="n">NearestNeighbor</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="s2">&quot;l2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find_nearest_neighbors</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">NearestNeighbor</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="s2">&quot;dot&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find_nearest_neighbors</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">NearestNeighbor</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="s2">&quot;cosine&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find_nearest_neighbors</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All tests passed&quot;</span><span class="p">)</span>


<span class="n">test_nearest_neighbors</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>All tests passed
</pre></div>
</div>
</div>
</div>
<p>Ở các phần sau của cuốn sách, chúng ta sẽ trực tiếp sử dụng module <a class="reference external" href="https://github.com/tiepvupsu/tabml/blob/master/tabml/utils/embedding.py"><code class="docutils literal notranslate"><span class="pre">tabml.utils.embedding</span></code></a> cho các tác vụ liên quan đến embedding.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_embedding"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../ch_data_processing/numeric_data.html" title="previous page">Đặc trưng dạng số (WIP)</a>
    <a class='right-next' id="next-link" href="word2vec.html" title="next page">Word2vec</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Tiep Vu<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            <div id="disqus_thread"></div>
  <script>
      /**
      *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
      *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
      /*
      var disqus_config = function () {
      this.page.url = machinelearningcoban.com;  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = tabml; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
      };
      */
      (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://tabml.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-89509207-2', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>