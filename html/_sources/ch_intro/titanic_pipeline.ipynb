{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74148a8c",
   "metadata": {},
   "source": [
    "# Pipeline đơn giản cho cuộc thi Titanic\n",
    "\n",
    "Trong trang này, tôi xin giới thiệu một pipeline hoàn thiện rất đơn giản để có thể tạo ra một bài nộp lên Kaggle và tính điểm. Tôi xin không đi sâu vào từng dòng lệnh mà muốn dùng ví dụ này để giúp các bạn có cái nhìn bao quát về một pipeline hoàn thiện.\n",
    "\n",
    "Toàn bộ mã nguồn của pipeline này có thể được tìm thấy [tại đây](https://github.com/tiepvupsu/tabml_book/tree/main/book/ch_intro/titanic_pipeline.py).\n",
    "\n",
    "\n",
    "Bước đầu tiên luôn luôn là import những thư viện cần thiết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f33c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbfcc8",
   "metadata": {},
   "source": [
    "Load dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "917b01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_path = (\n",
    "    \"https://media.githubusercontent.com/media/tiepvupsu/tabml_data/master/titanic/\"\n",
    ")\n",
    "df_train_full = pd.read_csv(titanic_path + \"train.csv\")\n",
    "df_test = pd.read_csv(titanic_path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84532f",
   "metadata": {},
   "source": [
    "Tiếp theo, ta cần bỏ đi những cột có quá nhiều giá trị bị khuyết. Sử dụng các giá trị này thường không mang lại sự cải thiện cho mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de85632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full.drop(columns=[\"Cabin\"])\n",
    "df_test.drop(columns=[\"Cabin\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a5545",
   "metadata": {},
   "source": [
    "Trước khi đi vào bước xây dựng đặc trưng, ta cần phân chia dữ liệu huấn luyện/kiểm định. Ở đây, 10% ngẫu nhiên của dữ liệu có nhãn ban đầu được tách ra làm dữ liệu kiểm định (_validation data_), 90% còn lại được giữ làm dữ liệu huấn luyện (_training data_). Cột `Survived` là cột nhãn được tách ra làm một biến riêng chứa nhãn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2372ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train_full, test_size=0.1)\n",
    "X_train = df_train.copy()\n",
    "y_train = X_train.pop(\"Survived\")\n",
    "\n",
    "X_val = df_val.copy()\n",
    "y_val = X_val.pop(\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba32c0",
   "metadata": {},
   "source": [
    "Sau khi đã phân chia dữ liệu, ta cần xử lý tạo các đặc trưng cho mô hình. Các đặc trưng hạng mục và đặc trưng số cần có những cách xử lý khác nhau. Với mỗi loại đặc trưng, ta cần hai bước nhỏ: (i) làm sạch dữ liệu và (ii) biến dữ liệu về dạng số phù hợp với đầu vào của mô hình. Trước hết là với dữ liệu dạng hạng mục, ở đây, `cat_transformer` được áp dụng lên cả ba đặc trưng hạng mục:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ee7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"Embarked\", \"Sex\", \"Pclass\"]\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cde367",
   "metadata": {},
   "source": [
    "Tiếp theo, ta áp dụng `num_transformer` lên hai đặc trưng số:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599350f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\", \"Fare\"]\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", KNNImputer(n_neighbors=5)), (\"scaler\", RobustScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b5e36",
   "metadata": {},
   "source": [
    "Kết hợp hai bộ xử lý đặc trưng lại để có một bộ xử lý đặc trưng hoàn thiện. Lớp `ColumnTransformer` trong scikit-learn giúp kết hợp các _transformers_ lại:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe10c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3bdbbf",
   "metadata": {},
   "source": [
    "Cuối cùng, ta kết hợp bộ xử lý đặc trưng `preprocessor` với một bộ phân loại đơn giản hay được sử dụng với dữ liệu dạng bảng là `RandomForestClassifier` để được một pipeline `full_pp` hoàn chỉnh bao gồm cả xử lý dữ liệu và mô hình. `full_pp` được _fit_ với dữ liệu huấn luyện `(X_train, y_train)` sau đó được dùng để áp dụng lên dữ liệu kiểm định:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aaaf8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on train data: 0.98\n",
      "Accuracy score on validation data: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Full training pipeline\n",
    "full_pp = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "# training\n",
    "full_pp.fit(X_train, y_train)\n",
    "\n",
    "# training metric\n",
    "y_train_pred = full_pp.predict(X_train)\n",
    "print(\n",
    "    f\"Accuracy score on train data: {accuracy_score(list(y_train), list(y_train_pred)):.2f}\"\n",
    ")\n",
    "\n",
    "# validation metric\n",
    "y_pred = full_pp.predict(X_val)\n",
    "print(\n",
    "    f\"Accuracy score on validation data: {accuracy_score(list(y_val), list(y_pred)):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a6567",
   "metadata": {},
   "source": [
    "Như vậy, cả _hệ thống_ này cho độ chính xác 98% trên tập huấn luyện và 83% trên tập kiểm định. Sự chênh lệch này chứng tỏ đã xảy ra hiện tượng [_overfitting_](https://machinelearningcoban.com/2017/03/04/overfitting/). Tạm gác vấn đề này sang một bên, chúng ta sử dụng hệ thống vừa thu được để đưa ra dự đoán cho dữ liệu của cuộc thi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09bcee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make submission\n",
    "preds = full_pp.predict(df_test)\n",
    "sample_submission = pd.read_csv(titanic_path + \"gender_submission.csv\")\n",
    "sample_submission[\"Survived\"] = preds\n",
    "sample_submission.to_csv(\"titanic_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d325bc",
   "metadata": {},
   "source": [
    "Sau khi file nộp bài `titanic_submission.cssv` được tạo, ta có thể thử xem kết quả trên Leadboard của Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b487e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!kaggle competitions submit -c titanic -f titanic_submission.csv -m \"simple submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a1ab8",
   "metadata": {},
   "source": [
    "Kết quả trên Leaderboard của cuộc thi cho bài nộp này là `0.74641`, không quá tệ cho một pipeline đơn giản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66c2427",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "!rm titanic_submission.csv"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "source_map": [
   12,
   23,
   34,
   38,
   44,
   48,
   51,
   55,
   62,
   66,
   74,
   78,
   83,
   87,
   94,
   98,
   118,
   122,
   128,
   132,
   135,
   139
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}